{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7d96f35",
   "metadata": {},
   "source": [
    "# Linguistic Analyses for Compositional Abstractions\n",
    "## Notebook 3: Forming conventions to talk about shared abstractions\n",
    "\n",
    "This notebook was written by Robert Hawkins.  \n",
    "Original modeling by Robert Hawkins, Will McCarthy, Cameron Holdaway, Haoliang Wang, and Judy Fan."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5299ba5b",
   "metadata": {},
   "source": [
    "### *NOTE: THIS NOTEBOOK SERVES AS THE INSTRUCTOR VERSION*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc403a5",
   "metadata": {},
   "source": [
    "In the previous notebook we inferred libraries of program fragments that correspond to the collection of part concepts people have in their heads as they step through the trials. For each trial we also generated programs that use these abstractions to express each scene more efficiently. Now we tackle the challenge of communicating these programs to another person. \n",
    "\n",
    "This is where language comes in. Words allow us to communicate arbitrarily complex concepts. Assuming that Architects and Builders learn the concepts over a trial sequence, each concept that is learned (each program fragment) could, in principle, be assigned a new word or phrase, and conveyed directly through the Architects' instructions. Well, almost. There is no guarantee that the words the Architect chooses to pick out a new concept would invoke the same concept in someone else. There is actually uncertainty about how the Builder will interpret the Architects' instructions and this, we suggest, might change what the Architect chooses to say.\n",
    "\n",
    "Our hypothesis is that Architects trade-off communicative *efficiency* with communicative *effectiveness*. While they generally want to say things concisely, if there is too much uncertainty about how the Builder will interpret their words, they will choose a less ambiguous (if more wordy) way of expressing the same information. Concretely, if the Architect wanted to say \"build an L\" but they thought that the Builder wouldn't get what \"L\" meant, they might spell out the steps to make an L-shaped tower instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1995be1",
   "metadata": {},
   "source": [
    "This notebook is divided into 3 sections:\n",
    "**Section 1** demonstrates how we represent lexicons-- mappings of program elements to words.  \n",
    "**Section 2** shows how we can program Architect and Builder agents to make decisions based on their lexicons.  \n",
    "**Section 3** shows how we can update velie"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cf1df7-e955-4a46-8be7-bd72d30c652f",
   "metadata": {},
   "source": [
    "## Setup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3fa8c9-e4bb-4963-a6d4-96fa3aeec6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import functools\n",
    "import itertools\n",
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from numpy.random import choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadc094a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import classes for our model\n",
    "sys.path.append(\"../model/convention_formation/\")\n",
    "from distribution import *\n",
    "from lexicon import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9647db22",
   "metadata": {},
   "source": [
    "### read program data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb67575",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_json('../data/model/programs_for_you/programs_ppt_1.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b9d279",
   "metadata": {},
   "source": [
    "## Section 1: Lexicons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e8da56-7f7c-494e-8b0a-fe9ca33a7d65",
   "metadata": {},
   "source": [
    "### Representing lexicons\n",
    "\n",
    "First we need a way to represent the mapping of part concepts to words in the Architects' and Builders' heads. \n",
    "\n",
    "We have defined a BlockLexicon class in `lexicon.py`, which stores the mapping of program primitives (from the previous section) to words and phrases.\n",
    "\n",
    "Let's take this class out for a drive. \n",
    "\n",
    "We initialize it with the primitives of the agent's DSL on a given trial and an (ordered) list of available lexemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84148612",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lexemes for program abstractions learned in previous section\n",
    "# in our example, only 5 distinct abstractions were learned, so we only need 5 additional lexemes\n",
    "lexemes = ['blah', 'blab', 'bloop', 'bleep', 'floop'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb79b25-0cb4-42fd-bac1-067bc15ea9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "dsl = d['dsl'][10]\n",
    "l = BlockLexicon(dsl, lexemes)\n",
    "print(dsl[0], '->', l.dsl_to_language(dsl[0]))\n",
    "print(dsl[10], '->', l.dsl_to_language(dsl[10]))\n",
    "print(dsl[-1], '->', l.dsl_to_language(dsl[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079c86e7-880f-4736-8029-1d32d9247fc0",
   "metadata": {},
   "source": [
    "and we can also go in the other direction, converting from language to programmatic \"concepts\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de665913-c211-4c9d-b001-09f2394c5683",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('place a horizontal block. ->', l.language_to_dsl('place a horizontal block.'))\n",
    "print('move to the left by 8 ->', l.language_to_dsl('move to the left by 8'))\n",
    "print('place a blah. ->', l.language_to_dsl('place a blah.'))\n",
    "print('place a flomp. ->', l.language_to_dsl('place a womp.'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4af5810-abbb-430e-aa96-62edd23e0b9b",
   "metadata": {},
   "source": [
    "### Representing beliefs about lexicons\n",
    "\n",
    "To model the Architect's word choice, we explicitly model their beliefs about the Builder's lexicon. We represent this as a distribution over a set of possible lexicons. For this example, we're going to manually construct a distribution as another dictionary (from lexicons to probabilities). (See `distribution.py` for the implementation if you're interested in how this works).\n",
    "\n",
    "Because our focus is on modeling abstractions learned during the task, we assume that Architect Agents and Builder Agents can unambiguously communicate about the base DSL-- moving left and right and placing individual blocks. I.e. when an Architect wants a Builder to place a block they will always say \"place a horizontal block\", and the Builder will correctly interpret this utterance.\n",
    "\n",
    "The only thing that varies across different lexicons is the words used for *learned* program fragments. In practice (for this example) only five of these were learned across all participants' trial sequences. The set of possible lexicons is therefore fully defined by the set of possible mappings from these fragments to the `lexemes` defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87b2f854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# construct full lexicon for all possible mappings\n",
    "possible_lexicons = [BlockLexicon(dsl, list(mapping)) for mapping in itertools.permutations(lexemes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e08889a-8c4d-4e7f-9764-290418abd69f",
   "metadata": {},
   "source": [
    "We define the Architects' and Builders' priors (their initial beliefs) as the uniform distribution over these lexicons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9355dc77-4b9f-478c-a41d-b55db4e16682",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior = UniformDistribution(possible_lexicons)\n",
    "\n",
    "print('Example lexicon')\n",
    "\n",
    "print('lexicon:', json.dumps(prior.support()[0], indent = 4))\n",
    "\n",
    "print('P(lexicon) =', prior.score(prior.support()[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "011da703",
   "metadata": {},
   "source": [
    "We can also marginalize to look at values of any particular chunk:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d432c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('possible values of chunk_L : ', \n",
    "      json.dumps(prior.marginalize(lambda d : d['chunk_L']), indent = 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d3f57f",
   "metadata": {},
   "source": [
    "The equal probabilities for each expression tell us that the Agents think each expression is an equally good (or bad) translation of \"chunk_L\". This makes sense for this artificial langauge (where \"bleeps\" and \"bloops\" are used to refer to abstractions). Real people likely have strong priors about what words will mean (we can make quite a lot of sense of \"build an L\" before any shared experience), but starting with a uniform prior provides a good starting point."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0009db83-2988-415b-84db-284895003536",
   "metadata": {},
   "source": [
    "## Section 2: Simulating Agents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55489f03",
   "metadata": {},
   "source": [
    "Now we have a way of representing beliefs over lexicons, we can define our Architect and Builder agents.\n",
    "\n",
    "Both maintain a set of possible lexicons, and belief distribution over the *other agent's* lexicon.\n",
    "\n",
    "The **Architect** agent makes choices about what to say based on it's beliefs about how the **Builder** will interpret them.  \n",
    "\n",
    "The **Builder** takes actions based on it's beliefs about what the **Architect's** utterances mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59a39bce-9691-437e-99d0-e53c453c2e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FixedAgent() :\n",
    "    def __init__(self, role, trial) :\n",
    "        self.role = role\n",
    "        self.actions = trial['dsl']\n",
    "\n",
    "        # initialize beliefs to uniform prior over lexicons\n",
    "        self.possible_lexicons = set([BlockLexicon(self.actions, list(mapping)) \n",
    "                                      for mapping in itertools.permutations(lexemes)])\n",
    "        \n",
    "#         print(lexemes)\n",
    "        self.beliefs = UniformDistribution(self.possible_lexicons)\n",
    "        self.utterances = set(list(self.possible_lexicons)[0].values())\n",
    "        \n",
    "    def act(self, observation) :\n",
    "        if self.role == 'architect' :\n",
    "            # get P(utt | target) by marginalizing over lexicons \n",
    "            utt_dist = EmptyDistribution()\n",
    "            for lexicon in self.beliefs.support() :\n",
    "                utt_dist.update({lexicon.dsl_to_language(observation) : self.beliefs.score(lexicon)})\n",
    "            return choice(a = [*utt_dist.support()], \n",
    "                          p = [utt_dist.score(u) for u in utt_dist.support()])\n",
    "\n",
    "        if self.role == 'builder' :\n",
    "            # get P(a | utt) by marginalizing over lexicons \n",
    "            action_dist = EmptyDistribution()\n",
    "            for lexicon in self.beliefs.support() :\n",
    "                action_dist.update({lexicon.language_to_dsl(observation) : self.beliefs.score(lexicon)})\n",
    "            return choice(a = [*action_dist.support()], \n",
    "                          p = [action_dist.score(a) for a in action_dist.support()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e777d9b9-1e58-4cd9-9dbf-90be88d60d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "architect = FixedAgent('architect', d.loc[0].to_dict())\n",
    "print('architect choice: ', architect.act('h'))\n",
    "\n",
    "builder = FixedAgent('builder', d.loc[0].to_dict())\n",
    "print('builder choice: ', builder.act('place a horizontal block.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352243eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "architect = FixedAgent('architect', d.loc[0].to_dict())\n",
    "print('architect choice: ', architect.act('chunk_L'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9020e990-db06-4ed1-ac7a-5f153c0c91b1",
   "metadata": {},
   "source": [
    "### Running simulations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "023b0db7-b394-4b59-ba16-c3177bc42ced",
   "metadata": {},
   "source": [
    "Now we have our agents, we need to run them forward through the trial sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567ff4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.04 # weight that trades off between TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5cafdc-5a6f-451f-a557-ea63c80dd4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_simulation() :\n",
    "    output = pd.DataFrame({\"utt\": [], \"response\": [], \"target_program\": [], \"target_length\" : [], \"acc\": []})\n",
    "    for i, trial in d.iterrows() :\n",
    "        architect = FixedAgent('architect', trial)\n",
    "        builder = FixedAgent('builder', trial)\n",
    "\n",
    "        # architect selects which program representation to comunicate proportional to length\n",
    "        possiblePrograms = list(trial['programs_with_length'].keys())\n",
    "        possibleLengths = np.array(list(trial['programs_with_length'].values()))\n",
    "        utilities = np.exp(-alpha * possibleLengths) / sum(np.exp(-alpha * possibleLengths))\n",
    "        target_program = choice(a = possiblePrograms, p = utilities)\n",
    "\n",
    "        # loop through steps of target program one at a time\n",
    "        utts, responses, accs = [], [], []\n",
    "        for step in target_program.split(' ') :\n",
    "            utt = architect.act(step)\n",
    "            response = builder.act(utt)\n",
    "            utts.append(utt)\n",
    "            responses.append(response)\n",
    "            accs.append(1.0 * (response == step))\n",
    "\n",
    "        output = pd.concat([output, pd.DataFrame({\n",
    "            \"trial\": int(i),\n",
    "            \"utt\": utts,\n",
    "            \"response\": responses,\n",
    "            \"acc\": accs,\n",
    "            \"target_program\": target_program,\n",
    "            \"target_length\" : trial['programs_with_length'][target_program],\n",
    "        })])\n",
    "    return output\n",
    "\n",
    "run_0 = run_simulation()\n",
    "display(run_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4699543",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's inspect the first trial\n",
    "print('target program: \\n', run_0.query('trial==0').loc[0,'target_program'])\n",
    "run_0.query('trial==0')[['utt','response','acc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cbf043",
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's inspect the final trial\n",
    "print('target program: \\n', run_0.query('trial==11').loc[0,'target_program'])\n",
    "\n",
    "run_0.query('trial==11')[['utt','response','acc']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6692312-fff3-4621-83b0-393c1f70268a",
   "metadata": {},
   "source": [
    "### <span style=\"color: orange\"> Exercise: explore how accuracy changes </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858a12ad-eac1-4c94-a115-2f10c42505f7",
   "metadata": {},
   "source": [
    "Wait, why is the accuracy so bad? Well, our agents aren't actually *learning* -- they're continuing to use their initial uniform priors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e771ae8-e64c-409d-8670-bfca342c043b",
   "metadata": {},
   "source": [
    "## Section 3: Simulating learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe82f26-4c60-451a-a2d5-4ab4f6fb9118",
   "metadata": {},
   "source": [
    "To have our agents learn, we need to extend the agent class to do Bayesian inference.\n",
    "\n",
    "Here we add an update_beliefs function, which performs a Bayesian update on the beliefs about the other agent's lexicon based on the outcome of the previous trial. Note that this update happens when the class is initialized, so really we're defining a new agent at each step with updated beliefs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfb28cf-8efd-4852-9110-998011ba7312",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LearningAgent(FixedAgent) :\n",
    "    def __init__(self, role, curr_trial, previous_trial_df) :\n",
    "        super().__init__(role, curr_trial)\n",
    "        combined_primitives = set().union(*previous_trial_df['dsl']) if not previous_trial_df.empty else self.actions\n",
    "        self.possible_lexicons = set([BlockLexicon(set().union(combined_primitives), list(mapping)) \n",
    "                                      for mapping in itertools.permutations(lexemes)])\n",
    "        self.utterances = set(list(self.possible_lexicons)[0].values())\n",
    "        self.update_beliefs(previous_trial_df)\n",
    "\n",
    "    def update_beliefs(self, previous_trial_df) :\n",
    "        # Initialize posterior \n",
    "        posterior = EmptyDistribution()\n",
    "        posterior.to_logspace()\n",
    "\n",
    "        # for each data point, calculate the marginal likelihood under lexicon distribution\n",
    "        # P(l | obs) = 1/Z * P(l) * \\prod_{o \\in obs} P(o | l)\n",
    "        # log P(l|obs) = -log Z + log P(l) + \\sum_{o \\in obs} log P(o | l)\n",
    "        for lexicon in self.beliefs.support() :\n",
    "            prior_term = np.log(self.beliefs.score(lexicon))\n",
    "            likelihood_term = 0\n",
    "            for i, step in previous_trial_df.iterrows() :\n",
    "                if self.role == 'builder' :\n",
    "                    likelihood_term += np.log(self.A1(step.target, lexicon).score(step.utterance))\n",
    "                elif self.role == 'architect' :\n",
    "                    likelihood_term += np.log(self.B0(step.utterance, lexicon).score(step.response))\n",
    "            posterior.update({lexicon : prior_term + likelihood_term})\n",
    "        posterior.renormalize()\n",
    "        posterior.from_logspace()\n",
    "        self.beliefs = posterior\n",
    "        \n",
    "    def B0(self, utt, lexicon) :\n",
    "        builder_dist = EmptyDistribution()\n",
    "        for action in self.actions :\n",
    "            builder_dist.update({action : 1 if action == lexicon.language_to_dsl(utt) else 0.01})\n",
    "        builder_dist.renormalize()\n",
    "        return builder_dist\n",
    "        \n",
    "    def A1(self, target, lexicon) :\n",
    "        architect_dist = EmptyDistribution()\n",
    "        for utt in self.utterances :\n",
    "            architect_dist.update({utt : 1 if utt == lexicon.dsl_to_language(target) else 0.01})\n",
    "        architect_dist.renormalize()\n",
    "        return architect_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c2c439-4adc-4194-a223-6bab282f3410",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_learning_simulation(verbose = False) :\n",
    "    output = pd.DataFrame({\"utterance\": [], \"response\": [], \"target\": [], \"full_program\" : [], \"target_length\" : [], \"dsl\" : [], \"acc\": []})\n",
    "    for i, trial in d.iterrows() :\n",
    "        architect = LearningAgent('architect', trial, output) # create agent with updated beliefs\n",
    "        builder = LearningAgent('builder', trial, output)     # create agent with updated beliefs\n",
    "        \n",
    "        # architect selects which program representation to comunicate proportional to length\n",
    "        possiblePrograms = list(trial['programs_with_length'].keys())\n",
    "        possibleLengths = np.array(list(trial['programs_with_length'].values()))\n",
    "        utilities = np.exp(-alpha * possibleLengths) / sum(np.exp(-alpha * possibleLengths))\n",
    "        target_program = choice(a = possiblePrograms, p = utilities)\n",
    "\n",
    "        # loop through steps of target program one at a time\n",
    "        target_steps, utts, responses, accs = [], [], [], []\n",
    "        for step in target_program.split(' ') :\n",
    "            utt = architect.act(step)\n",
    "            response = builder.act(utt)\n",
    "            target_steps.append(step)\n",
    "            utts.append(utt)\n",
    "            responses.append(response)\n",
    "            accs.append(response == step)\n",
    "\n",
    "        if verbose:\n",
    "            print('trial', i)\n",
    "            print(pd.DataFrame({'utts' : utts, 'responses' : responses, 'correct' : accs, 'target' : target_steps}))\n",
    "            print('beliefs about chunk_C meaning', \n",
    "                  json.dumps(architect.beliefs.marginalize(lambda d : d['chunk_C'] if 'chunk_C' in d else None), indent = 4))\n",
    "        \n",
    "        output = pd.concat([output, pd.DataFrame({\n",
    "            \"trial\": i,\n",
    "            \"utterance\": utts,\n",
    "            \"response\": responses,\n",
    "            \"acc\": accs,\n",
    "            \"target\" : target_steps,\n",
    "            \"full_program\": target_program,\n",
    "            \"dsl\" : [trial['dsl']] * len(utts),\n",
    "            \"target_length\" : trial['programs_with_length'][target_program],\n",
    "        })])\n",
    "    return output\n",
    "\n",
    "learning_run_0 = run_learning_simulation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3f9240",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_run_0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78473d56-4367-4db1-9445-5de7e7dc6b13",
   "metadata": {},
   "source": [
    "### Jointly choose program and utterance\n",
    "\n",
    "Wow, this is great! We can see our agents are updating their beliefs about the lexicon over time and able to get somewhat more accurate as they coordinate. But one of the most interesting things about our empirical data is that speakers seem to be strategically choosing which representation of the tower to convey -- our best current theory of why participants reduce the length of their utterances over time is that even when new library chunks come online, architects don't always try to refer to them right away. They aren't confident enough that their partner will understand, as the block-level descriptions are much safer. However, the block-level descriptions are also much *costlier* in terms of time and effect because they have to laboriously describe one action at a time. \n",
    "\n",
    "So far, we just used a placeholder for how the speaker picks which representation to communication: they just randomly pick from the list of candidates, slightly preferring shorter programs. However, there are other considerations that ought to go into this decision, namely the estimated likelihood that the listener will do the right thing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5d524d4-92bf-4013-a842-bed42df01678",
   "metadata": {},
   "source": [
    "As an exercise, add one line of code to the simulation to weight the target program according to its utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c1b7c8-7e3b-4732-b4b1-12baa57c82b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_strategic_simulation() :\n",
    "    output = pd.DataFrame({\"utterance\": [], \"response\": [], \"target\": [], \"full_program\" : [], \"target_length\" : [], \"dsl\" : [], \"acc\": []})\n",
    "    for i, trial in d.iterrows() :\n",
    "        architect = LearningAgent('architect', trial, output)\n",
    "        builder = LearningAgent('builder', trial, output)\n",
    "        \n",
    "        # architect selects which program representation to comunicate proportional to length\n",
    "        possiblePrograms = list(trial['programs_with_length'].keys())\n",
    "        possibleLengths = np.array(list(trial['programs_with_length'].values()))\n",
    "        \n",
    "        ## \n",
    "        ## utilities = np.exp(-alpha * possibleLengths) / sum(np.exp(-alpha * possibleLengths))\n",
    "        ## \n",
    "        \n",
    "        target_program = choice(a = possiblePrograms, p = utilities)\n",
    "\n",
    "        # loop through steps of target program one at a time\n",
    "        target_steps, utts, responses, accs = [], [], [], []\n",
    "        for step in target_program.split(' ') :\n",
    "            utt = architect.act(step)\n",
    "            response = builder.act(utt)\n",
    "            target_steps.append(step)\n",
    "            utts.append(utt)\n",
    "            responses.append(response)\n",
    "            accs.append(response == step)\n",
    "\n",
    "        print('trial', i)\n",
    "        print(pd.DataFrame({'utts' : utts, 'responses' : responses, 'correct' : accs, 'target' : target_steps}))\n",
    "        print('beliefs about chunk_C meaning', \n",
    "              json.dumps(architect.beliefs.marginalize(lambda d : d['chunk_C'] if 'chunk_C' in d else None), indent = 4))\n",
    "        output = pd.concat([output, pd.DataFrame({\n",
    "            \"utterance\": utts,\n",
    "            \"response\": responses,\n",
    "            \"acc\": accs,\n",
    "            \"target\" : target_steps,\n",
    "            \"full_program\": target_program,\n",
    "            \"dsl\" : [trial['dsl']] * len(utts),\n",
    "            \"target_length\" : trial['programs_with_length'][target_program],\n",
    "        })])\n",
    "    return output\n",
    "display(run_learning_simulation())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136ad286",
   "metadata": {},
   "source": [
    "### Summary\n",
    "\n",
    "\n",
    "Congratulations! You've finished the tutorial!\n",
    "\n",
    "We hope you found it fun and informative."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ca_tut",
   "language": "python",
   "name": "ca_tut"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
